{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.file_utils:PyTorch version 1.4.0 available.\n",
      "INFO:transformers.file_utils:TensorFlow version 2.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from transformers import (\n",
    "    DataProcessor,\n",
    "    InputExample,\n",
    "    BertTokenizer,\n",
    "    BertConfig,\n",
    "    BertForSequenceClassification,\n",
    "    glue_convert_examples_to_features,\n",
    ")\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_random_seed(2020)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>entity</th>\n",
       "      <th>offset</th>\n",
       "      <th>short_text</th>\n",
       "      <th>kb_id</th>\n",
       "      <th>kb_text</th>\n",
       "      <th>kb_predicate_num</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>小品</td>\n",
       "      <td>0</td>\n",
       "      <td>小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人</td>\n",
       "      <td>275897</td>\n",
       "      <td>义项描述:小品 代表:喜剧小品 中文名:小品 特点:短小精悍，情节简单等 基本要求:语言清晰...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>吴京</td>\n",
       "      <td>10</td>\n",
       "      <td>小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人</td>\n",
       "      <td>218699</td>\n",
       "      <td>摘要:吴京，男，1963年4月出生，河北石家庄人，1986年2月加入中国共产党，1980年6...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>吴京</td>\n",
       "      <td>10</td>\n",
       "      <td>小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人</td>\n",
       "      <td>200103</td>\n",
       "      <td>性别:男 毕业院校:楚雄州人民警察学校 出生日期:1980年10月 职务:公安局科技信息化和...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>吴京</td>\n",
       "      <td>10</td>\n",
       "      <td>小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人</td>\n",
       "      <td>159056</td>\n",
       "      <td>职业:演员、导演 义项描述:中国内地男演员、导演 配偶:谢楠 国籍:中国 代表作品:流浪地球...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>障碍</td>\n",
       "      <td>16</td>\n",
       "      <td>小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人</td>\n",
       "      <td>249920</td>\n",
       "      <td>性质:体育竞技术语 日本語:障害　しょうがい 义项描述:体育竞技术语 距起跑点:270米 外...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id entity  offset                      short_text   kb_id  \\\n",
       "0        1     小品       0  小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人  275897   \n",
       "1        1     吴京      10  小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人  218699   \n",
       "2        1     吴京      10  小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人  200103   \n",
       "3        1     吴京      10  小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人  159056   \n",
       "4        1     障碍      16  小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人  249920   \n",
       "\n",
       "                                             kb_text  kb_predicate_num  \\\n",
       "0  义项描述:小品 代表:喜剧小品 中文名:小品 特点:短小精悍，情节简单等 基本要求:语言清晰...                 8   \n",
       "1  摘要:吴京，男，1963年4月出生，河北石家庄人，1986年2月加入中国共产党，1980年6...                 9   \n",
       "2  性别:男 毕业院校:楚雄州人民警察学校 出生日期:1980年10月 职务:公安局科技信息化和...                10   \n",
       "3  职业:演员、导演 义项描述:中国内地男演员、导演 配偶:谢楠 国籍:中国 代表作品:流浪地球...                17   \n",
       "4  性质:体育竞技术语 日本語:障害　しょうがい 义项描述:体育竞技术语 距起跑点:270米 外...                 8   \n",
       "\n",
       "   predict  \n",
       "0        1  \n",
       "1        0  \n",
       "2        0  \n",
       "3        1  \n",
       "4        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_path = '../../data/tsv/'\n",
    "train_data = pd.read_csv(tsv_path+'EL_TRAIN.tsv', sep='\\t')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityLinkingProcessor(DataProcessor):\n",
    "\n",
    "    def get_train_examples(self, file_path):\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(file_path),\n",
    "            set_type='train',\n",
    "        )\n",
    "\n",
    "    def get_dev_examples(self, file_path):\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(file_path),\n",
    "            set_type='valid',\n",
    "        )\n",
    "    \n",
    "    def get_test_examples(self, file_path):\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(file_path),\n",
    "            set_type='test',\n",
    "        )\n",
    "\n",
    "    def get_labels(self):\n",
    "        return ['0', '1']\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        examples = []\n",
    "        for i, line in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = f'{set_type}-{i}'\n",
    "            text_a = line[1] + ' ' + line[3]\n",
    "            text_b = line[5]\n",
    "            label = line[-1]  \n",
    "            examples.append(InputExample(\n",
    "                guid=guid,\n",
    "                text_a=text_a,\n",
    "                text_b=text_b,\n",
    "                label=label,\n",
    "            ))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputExample(guid='train-11', text_a='甄嬛传 甄嬛传：安陵容怀孕时，雍正经常摸她的肚子，原来这动作大有深意', text_b='摘要:《甄嬛传》是经小说原作者流潋紫改编的一个新话剧，首度用戏剧的形式展现一个史诗类题材。 义项描述:话剧版《甄嬛传》', label='0')\n",
      "Train: 535333\n",
      "\n",
      "InputExample(guid='valid-21', text_a='中国作家 《中国作家》2013年度排行榜', text_b='中文名:中国作家 摘要:中国作家主要指中国现、当代作家。 起始:五四时期 标签:文化 包括:中国现当代作家 义项描述:作家分类 代表:鲁迅，朱自清', label='1')\n",
      "Valid: 142939\n",
      "\n",
      "InputExample(guid='test-31', text_a='妹妹 思追原来是个超级妹控，不愿妹妹嫁人，然而妹妹却喜欢一博老师', text_b='片长:8分4秒 外文名:Sister 主演:刘炳阳 编剧:宋思琪 imdb编码:tt9032798 色彩:黑白 义项描述:中国/美国2018年宋思琪执导影片 类型:动画电影 导演:宋思琪 出品公司:The Animation Showcase 发行公司:The Animation Showcase 制片地区:中国、美国 对白语言:普通话 摘要:《妹妹》是由宋思琪执导，刘炳阳参与配音的动画电影，该片于2018年6月15日在法国安纳西国际动画电影节上映。 上映时间:2018年6月15日（安纳西国际动画电影节） 中文名:妹妹', label='0')\n",
      "Test: 309442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processor = EntityLinkingProcessor()\n",
    "\n",
    "train_examples = processor.get_train_examples(tsv_path + 'EL_TRAIN.tsv')\n",
    "print(train_examples[10])\n",
    "print('Train:', len(train_examples))\n",
    "print()\n",
    "\n",
    "valid_examples = processor.get_dev_examples(tsv_path + 'EL_VALID.tsv')\n",
    "print(valid_examples[20])\n",
    "print('Valid:', len(valid_examples))\n",
    "print()\n",
    "\n",
    "test_examples = processor.get_test_examples(tsv_path + 'EL_TEST.tsv')\n",
    "print(test_examples[30])\n",
    "print('Test:', len(test_examples))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(examples, \n",
    "                      tokenizer, \n",
    "                      max_length=384, \n",
    "                      shuffle=False,\n",
    "                      batch_size=32,\n",
    "                      num_workers=6):\n",
    "    features = glue_convert_examples_to_features(\n",
    "        examples,\n",
    "        tokenizer,\n",
    "        label_list=['0', '1'],\n",
    "        max_length=max_length,\n",
    "        output_mode='classification',\n",
    "        pad_on_left=False,\n",
    "        pad_token=tokenizer.pad_token_id,\n",
    "        pad_token_segment_id=0,\n",
    "    )\n",
    "    \n",
    "    dataset = torch.utils.data.TensorDataset(\n",
    "        torch.LongTensor([f.input_ids for f in features]),\n",
    "        torch.LongTensor([f.attention_mask for f in features]),\n",
    "        torch.LongTensor([f.token_type_ids for f in features]),\n",
    "        torch.LongTensor([f.label for f in features])\n",
    "    )\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        shuffle=shuffle, \n",
    "        batch_size=32, \n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils:Model name '/media/bnu/data/transformers-pretrained-model/chinese_roberta_wwm_ext_pytorch/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '/media/bnu/data/transformers-pretrained-model/chinese_roberta_wwm_ext_pytorch/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "INFO:transformers.tokenization_utils:Didn't find file /media/bnu/data/transformers-pretrained-model/chinese_roberta_wwm_ext_pytorch/added_tokens.json. We won't load it.\n",
      "INFO:transformers.tokenization_utils:Didn't find file /media/bnu/data/transformers-pretrained-model/chinese_roberta_wwm_ext_pytorch/special_tokens_map.json. We won't load it.\n",
      "INFO:transformers.tokenization_utils:Didn't find file /media/bnu/data/transformers-pretrained-model/chinese_roberta_wwm_ext_pytorch/tokenizer_config.json. We won't load it.\n",
      "INFO:transformers.tokenization_utils:loading file /media/bnu/data/transformers-pretrained-model/chinese_roberta_wwm_ext_pytorch/vocab.txt\n",
      "INFO:transformers.tokenization_utils:loading file None\n",
      "INFO:transformers.tokenization_utils:loading file None\n",
      "INFO:transformers.tokenization_utils:loading file None\n",
      "INFO:transformers.data.processors.glue:Writing example 0/535333\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: train-1\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 2207 1501 2207 1501 517 2773 4331 3125 752 518 704 8024 1426 776 4960 4788 7028 7028 7397 4809 6237 3131 4263 782 8024 3918 2658 1440 4635 1922 2697 782 102 721 7555 2989 6835 131 2207 1501 807 6134 131 1599 1196 2207 1501 704 3152 1399 131 2207 1501 4294 4157 131 4764 2207 5125 2636 8024 2658 5688 5042 1296 5023 1825 3315 6206 3724 131 6427 6241 3926 3251 8024 2501 2578 5632 4197 5023 4028 5686 3800 2692 752 7555 131 6716 2552 3123 3351 8024 5632 928 3036 6206 131 2207 1501 8024 2218 3221 2207 4638 5686 3318 1501 511 3403 5041 131 6427 6241 510 3152 2110 510 3289 5686 510 2767 1196 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:label: 1 (id = 1)\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: train-2\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 1426 776 2207 1501 517 2773 4331 3125 752 518 704 8024 1426 776 4960 4788 7028 7028 7397 4809 6237 3131 4263 782 8024 3918 2658 1440 4635 1922 2697 782 102 3036 6206 131 1426 776 8024 4511 8024 9155 2399 125 3299 1139 4495 8024 3777 1266 4767 2157 2411 782 8024 8629 2399 123 3299 1217 1057 704 1744 1066 772 1054 8024 8499 2399 127 3299 1346 1217 2339 868 8024 1920 2110 3315 4906 2110 1325 8024 3862 1298 1298 3862 5664 7339 5661 4958 1070 1333 1346 6450 7270 1221 4415 8020 1199 2360 5277 8021 6760 689 511 1139 4495 1765 131 3777 1266 4767 2157 2411 1139 4495 3189 3309 131 9155 2399 125 3299 928 814 131 1066 772 712 721 2595 1166 131 4511 721 7555 2989 6835 131 3777 1266 4689 1765 4415 928 2622 2229 1199 2229 7270 510 1146 1054 5299 2768 1447 3403 5041 131 6121 689 782 4289 510 782 4289 1744 5093 131 704 1744 704 3152 1399 131 1426 776 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:label: 0 (id = 0)\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: train-3\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 1426 776 2207 1501 517 2773 4331 3125 752 518 704 8024 1426 776 4960 4788 7028 7028 7397 4809 6237 3131 4263 782 8024 3918 2658 1440 4635 1922 2697 782 102 2595 1166 131 4511 3684 689 7368 3413 131 3504 7413 2336 782 3696 6356 2175 2110 3413 1139 4495 3189 3309 131 8499 2399 8108 3299 5466 1218 131 1062 2128 2229 4906 2825 928 2622 1265 1469 2825 3318 4906 4906 7270 704 3152 1399 131 1426 776 1744 5093 131 704 1744 3403 5041 131 6121 689 782 4289 510 782 4289 3696 3184 131 3727 3184 3036 6206 131 1426 776 8024 4511 8024 3727 3184 8024 8499 2399 8108 3299 1139 4495 8024 4385 1062 2128 2229 4906 2825 928 2622 1265 1469 2825 3318 4906 4906 7270 511 721 7555 2989 6835 131 1062 2128 2229 4906 2825 928 2622 1265 1469 2825 3318 4906 4906 7270 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:label: 0 (id = 0)\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: train-4\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 1426 776 2207 1501 517 2773 4331 3125 752 518 704 8024 1426 776 4960 4788 7028 7028 7397 4809 6237 3131 4263 782 8024 3918 2658 1440 4635 1922 2697 782 102 5466 689 131 4028 1447 510 2193 4028 721 7555 2989 6835 131 704 1744 1079 1765 4511 4028 1447 510 2193 4028 6981 981 131 6468 3507 1744 5093 131 704 1744 807 6134 868 1501 131 3837 3857 1765 4413 510 2773 4331 364 510 2773 4331 510 4331 4280 510 3324 4788 4331 123 510 4511 1036 3315 5682 510 2208 3360 3636 4374 510 2207 3330 7607 1143 510 1922 3353 2134 2360 510 1912 3152 1399 131 10266 10552 510 297 13005 288 13474 10945 8020 7506 6427 8021 5307 5279 1062 1385 131 7509 1290 2031 727 3036 6206 131 1426 776 8024 9072 2399 125 3299 124 3189 1139 4495 754 1266 776 8024 3684 689 754 1266 776 860 5509 1920 2110 511 704 3152 1399 131 1426 776 3696 3184 131 4007 3184 1139 4495 1765 131 1266 776 1139 4495 3189 3309 131 9072 2399 125 3299 124 3189 3403 5041 131 2031 727 782 4289 510 782 4289 510 2193 4028 510 4028 1447 712 6206 2768 2218 131 5018 8226 2237 1920 830 4510 2512 4636 5709 1946 3297 881 2193 4028 1946 2990 1399 117 5018 8252 2237 1378 3968 4510 2512 7032 7716 1946 3297 881 4511 6981 6235 1946 2990 1399 117 5018 122 2237 2768 7987 4510 2512 1453 3297 881 1220 868 4511 4028 1447 1946 117 5018 8226 2237 1920 830 4510 2512 4636 5709 1946 3297 881 5356 1196 1946 2990 1399 117 5018 8130 2237 1266 776 1920 2110 4495 4510 2512 5688 3297 881 1905 1957 868 1946 117 5018 8113 2237 1290 7959 1946 3297 3297 881 3173 7229 2193 4028 1946 117 5018 1724 2237 692 5339 722 6662 1744 7354 4510 2512 5688 4960 1139 6567 4346 702 782 1946 117 4886 2357 3172 704 1744 1355 2357 9160 1399 782 3528 8024 855 1154 5018 122 6716 7770 131 9251 8341 3684 689 7368 3413 131 1266 776 860 5509 1920 2110 3215 2429 131 4635 5399 2429 102 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:label: 1 (id = 1)\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: train-5\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 7397 4809 2207 1501 517 2773 4331 3125 752 518 704 8024 1426 776 4960 4788 7028 7028 7397 4809 6237 3131 4263 782 8024 3918 2658 1440 4635 1922 2697 782 102 2595 6574 131 860 5509 4993 2825 3318 6427 3189 3315 6295 131 7397 2154 547 11663 8261 8524 721 7555 2989 6835 131 860 5509 4993 2825 3318 6427 6655 6629 6651 4157 131 9282 5101 1912 3152 1399 131 11643 9283 8642 704 3152 1399 131 7397 4809 3403 5041 131 4495 3833 3318 6427 510 4495 3833 510 4852 833 3036 6206 131 7397 4809 8020 5739 3152 1399 8038 11643 9283 8642 8021 3221 671 4905 860 5509 4993 2825 3318 6427 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.data.processors.glue:label: 0 (id = 0)\n",
      "INFO:transformers.data.processors.glue:Writing example 10000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 20000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 30000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 40000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 50000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 60000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 70000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 80000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 90000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 100000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 110000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 120000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 130000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 140000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 150000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 160000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 170000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 180000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 190000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 200000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 210000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 220000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 230000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 240000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 250000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 260000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 270000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 280000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 290000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 300000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 310000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 320000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 330000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 340000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 350000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 360000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 370000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 380000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 390000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 400000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 410000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 420000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 430000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 440000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 450000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 460000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 470000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 480000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 490000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 500000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 510000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 520000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 530000/535333\n",
      "INFO:transformers.data.processors.glue:Writing example 0/142939\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: valid-1\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 1921 678 3766 3300 679 3141 4638 2155 2375 1921 678 3766 3300 679 3141 4638 2155 2375 118 446 9775 7437 704 2359 446 9775 102 1419 721 131 1730 5471 3221 4685 2190 4638 8024 5303 4955 6206 1146 4895 4638 511 3403 5041 131 3152 1265 2894 7509 131 9654 8244 13135 8139 10552 144 8207 9542 12066 8171 13135 3036 6206 131 517 7555 5417 185 3315 5279 518 3221 3300 6821 702 2692 2590 8024 852 100 1921 678 3187 3300 679 3141 5038 2375 100 3221 5436 6406 1400 4638 6413 8024 679 3221 1333 3152 4638 1139 1905 511 721 7555 2989 6835 131 1921 678 3766 3300 679 3141 4638 2155 2375 704 3152 1399 131 1921 678 3766 3300 679 3141 4638 2155 2375 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:label: 1 (id = 1)\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: valid-2\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 3719 1649 3719 1649 1322 2791 1139 4909 102 704 3152 1399 131 3719 1649 3036 6206 131 3719 1649 738 4500 868 2399 1384 8024 1325 1380 677 4500 6814 697 3613 511 721 7555 2989 6835 131 2370 4374 2399 1384 3403 5041 131 1325 1380 2595 6574 131 2370 4374 2399 1384 3308 807 131 6205 3232 510 1920 4415 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:label: 0 (id = 0)\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: valid-3\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 3719 1649 3719 1649 1322 2791 1139 4909 102 6860 686 3189 3309 131 1062 1039 8459 8152 2399 1139 4495 3189 3309 131 1062 1039 8347 8157 2399 5466 689 131 1014 782 807 6134 868 1501 131 517 3719 1649 6395 6887 3625 518 721 7555 2989 6835 131 1538 3308 3198 3309 1014 901 1744 5093 131 704 1744 3403 5041 131 782 4289 1139 4495 1765 131 3719 1649 8020 791 3946 2336 8021 928 814 131 867 3136 704 3152 1399 131 3719 1649 3036 6206 131 3719 1649 4883 2360 8020 1062 1039 8347 8157 2399 100 100 8459 8152 2399 8021 8024 3719 1649 8020 791 3946 2336 8021 782 8024 3221 1063 4862 2669 5543 4638 3791 1632 8024 4883 2134 4917 722 711 100 5018 676 1282 1724 807 4696 6230 4883 2360 100 8024 3791 1399 4371 6230 8024 1384 3209 6887 511 1912 3152 1399 131 9266 11672 8533 8354 3696 3184 131 3727 3184 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:label: 0 (id = 0)\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: valid-4\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 3719 1649 3719 1649 1322 2791 1139 4909 102 4294 772 131 6205 4478 5384 1778 3449 4819 5813 7676 3384 3719 1649 7931 7660 2792 2247 1765 1277 131 704 1744 1290 691 678 6785 1765 1277 131 128 6125 6887 8111 7252 125 740 3124 2424 7728 1765 131 677 1851 704 2552 1814 1277 1266 1814 6125 6887 1344 1184 6662 8416 1384 704 3152 1399 4917 131 3719 1649 1344 6934 3124 1277 4772 131 10838 8823 6121 3124 807 4772 131 9611 8709 8159 1166 1399 131 3719 2123 1765 4415 855 5390 131 3851 3736 4689 1298 6956 8024 3946 2336 2356 1266 6956 8024 4484 3736 678 3952 721 7555 2989 6835 131 3851 3736 4689 3946 2336 2356 678 6785 1344 3036 6206 131 3719 1649 1344 8024 704 1744 3851 3736 4689 3946 2336 2356 678 6785 4638 671 702 1344 8024 855 754 3851 3736 4689 691 1298 6956 8024 4484 3736 678 3952 1266 2279 8024 691 6943 727 3926 510 7942 2272 8024 6205 6825 7471 4506 510 5358 756 8024 1266 2970 803 2233 8024 1298 680 3946 2336 2356 1277 7392 3736 4685 3307 511 1344 1999 741 6381 131 4374 2506 5813 1912 3152 1399 4917 131 167 9142 12095 8139 13088 5865 1399 3250 4157 131 3507 3983 3736 8024 1724 3862 2255 4125 6756 4991 131 3719 1649 4125 6756 4991 782 1366 131 8460 119 8419 674 8020 8112 2399 2382 857 782 1366 8021 4510 6413 1277 1384 131 8137 8959 3698 952 3340 816 131 762 4178 2372 2108 7599 3698 952 3175 6241 131 1426 6427 118 3946 2336 6413 3322 1767 131 3946 2336 7987 3968 1744 7354 3322 1767 4761 1399 821 689 131 2146 6809 7415 1730 6631 6809 2845 1599 7881 1952 2434 7481 4916 131 11023 8156 2398 3175 1062 7027 1765 3403 131 7344 3825 3717 7316 2339 4923 6756 4277 807 4772 131 3851 145 6121 3124 1277 5102 1166 131 1344 1351 1962 1814 2356 131 1187 7323 1344 100 1344 7452 6937 1344 1166 4917 131 4484 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:label: 1 (id = 1)\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: valid-5\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 1322 2791 3719 1649 1322 2791 1139 4909 102 721 7555 2989 6835 131 2339 689 1322 2791 3403 5041 131 4852 833 510 4495 3833 1313 5709 4925 131 2600 817 4638 121 119 8137 110 8039 3036 6206 131 2339 689 1322 2791 8024 2900 4684 2970 4500 754 4495 772 2772 711 4495 772 6981 1947 4638 1392 4905 2791 2238 8024 1259 2886 712 6206 6756 7313 510 6774 1221 4500 2791 1350 7353 2247 6392 3177 4500 2791 511 704 3152 1399 131 2339 689 1322 2791 1943 4925 131 2600 817 4638 124 110 8039 4633 6381 6589 131 8209 1039 120 816 8039 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:label: 1 (id = 1)\n",
      "INFO:transformers.data.processors.glue:Writing example 10000/142939\n",
      "INFO:transformers.data.processors.glue:Writing example 20000/142939\n",
      "INFO:transformers.data.processors.glue:Writing example 30000/142939\n",
      "INFO:transformers.data.processors.glue:Writing example 40000/142939\n",
      "INFO:transformers.data.processors.glue:Writing example 50000/142939\n",
      "INFO:transformers.data.processors.glue:Writing example 60000/142939\n",
      "INFO:transformers.data.processors.glue:Writing example 70000/142939\n",
      "INFO:transformers.data.processors.glue:Writing example 80000/142939\n",
      "INFO:transformers.data.processors.glue:Writing example 90000/142939\n",
      "INFO:transformers.data.processors.glue:Writing example 100000/142939\n",
      "INFO:transformers.data.processors.glue:Writing example 110000/142939\n",
      "INFO:transformers.data.processors.glue:Writing example 120000/142939\n",
      "INFO:transformers.data.processors.glue:Writing example 130000/142939\n",
      "INFO:transformers.data.processors.glue:Writing example 140000/142939\n",
      "INFO:transformers.data.processors.glue:Writing example 0/309442\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: test-1\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 3360 2398 722 3360 2398 722 5031 2418 2277 4130 4396 2845 790 722 752 8024 794 7270 6369 6379 8024 2360 2023 2682 808 4316 1103 749 102 3636 1216 131 1290 2255 1187 3791 510 6792 6932 1187 3791 7448 1921 2958 6981 7509 131 7970 4142 120 3319 2094 5473 120 1306 4426 120 5722 2487 3152 120 2476 3345 120 1071 800 1399 4917 131 2207 3360 2094 510 2398 1036 510 2398 2475 510 3360 2360 2475 1052 4267 2399 7977 131 8131 118 8128 2259 721 7555 2989 6835 131 517 5010 1000 3736 3959 518 4638 782 4289 4673 1351 131 2340 1107 4883 1227 2548 6437 2595 1166 131 4511 4266 3678 131 3360 7448 1298 510 4374 1923 782 1988 2094 131 2277 4130 4396 704 3152 1399 131 3360 2398 722 4862 4266 131 3360 815 7413 3403 5041 131 3152 1265 782 4289 510 5994 2877 782 4289 510 782 4289 510 3152 2110 2501 6496 1912 1062 131 4374 1039 7464 7652 4028 131 5869 4383 510 1155 2454 3175 510 862 2140 4495 510 3330 6237 510 2129 6809 3696 510 1453 1159 3209 510 5101 3875 510 7357 3236 510 7357 3733 2360 4266 131 2277 679 5408 790 782 131 2277 679 5408 510 865 3771 3862 510 3312 7770 2292 3036 6206 131 3360 2398 722 3221 7032 2435 3636 899 2207 6432 517 5010 1000 3736 3959 518 704 4638 782 4289 511 5093 6581 131 4886 2456 4689 4886 2336 2356 7305 3836 131 4886 2014 7259 2229 8024 1290 2255 3836 4633 1767 868 1501 131 7032 2435 3636 899 2207 6432 517 5010 1000 3736 3959 518 1350 1071 6122 4495 868 1501 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:label: 0 (id = 0)\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: test-2\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 2277 4130 4396 3360 2398 722 5031 2418 2277 4130 4396 2845 790 722 752 8024 794 7270 6369 6379 8024 2360 2023 2682 808 4316 1103 749 102 2595 1166 131 1957 1071 800 1399 4917 131 2207 2360 1987 8024 4396 1036 8024 2360 1995 8024 2277 1996 2023 510 5855 2138 1036 1912 3152 1399 131 10825 8154 10061 12772 8171 721 7555 2989 6835 131 517 5010 1000 3736 3959 518 704 4638 782 4289 3036 6206 131 2277 4130 4396 3221 7032 2435 3636 899 2207 6432 517 5010 1000 3736 3959 518 704 4638 2650 1196 2466 782 4289 8024 1139 1767 6581 4959 1059 741 1724 1146 722 676 511 704 3152 1399 131 2277 4130 4396 4633 1767 868 1501 131 7032 2435 3636 899 2207 6432 517 5010 1000 3736 3959 518 2399 7977 131 1139 1767 8123 2259 8024 3647 3198 8113 2259 7652 4028 131 2411 5799 8020 8774 2399 704 1744 7676 3949 4510 2512 8021 117 2774 5401 4397 8020 8655 2399 704 1744 7676 3949 4510 6228 1196 8021 117 2418 7023 4130 8020 8630 2399 704 1744 1378 3968 4510 6228 1196 8021 117 1383 4997 8020 8431 2399 704 1744 7676 3949 4510 2512 8021 117 3330 1649 3615 8020 8508 2399 704 1744 7676 3949 4510 2512 8021 117 7357 2208 7459 8020 8432 2399 704 1744 7676 3949 4510 6228 1196 8021 117 7357 2548 2159 8020 8202 2399 704 1744 1378 3968 4510 6228 1196 8021 117 3330 7239 3449 8020 8202 2399 3173 1217 1786 4510 6228 1196 8021 117 5728 734 734 8020 8285 2399 704 1744 1079 1765 4510 6228 1196 8021 117 3342 5900 8020 8138 2399 704 1744 1079 1765 4510 6228 1196 8021 117 2002 3452 3173 8020 8271 2399 704 1744 1079 1765 4510 6228 1196 8021 3403 5041 131 782 4289 510 3152 2110 2501 6496 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:label: 0 (id = 0)\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: test-3\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 2360 2023 3360 2398 722 5031 2418 2277 4130 4396 2845 790 722 752 8024 794 7270 6369 6379 8024 2360 2023 2682 808 4316 1103 749 102 7025 721 131 2190 2360 4266 1988 2094 4638 4917 1461 3036 5632 131 517 5273 4128 6381 518 3036 6206 131 2360 2023 8024 6438 868 11772 10560 8688 8024 3727 6427 6404 6427 8024 3221 2190 2360 4266 1988 2094 4638 4917 1461 511 704 3152 1399 131 2360 2023 6438 7509 131 11772 10560 8688 1166 4917 131 2360 3678 3403 5041 131 6427 6241 510 2099 6404 721 7555 2989 6835 131 2360 2023 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:label: 0 (id = 0)\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: test-4\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 808 4316 1103 3360 2398 722 5031 2418 2277 4130 4396 2845 790 722 752 8024 794 7270 6369 6379 8024 2360 2023 2682 808 4316 1103 749 102 3403 5041 131 3636 899 2207 6432 712 6206 2768 2218 131 1140 3324 691 3175 679 6571 8024 7349 3632 3636 3360 1220 744 6981 981 131 818 4659 4659 4263 1962 131 1600 6983 8024 2486 4433 3036 6206 131 808 4316 1103 8024 3221 7032 2435 3636 899 2207 6432 517 5010 1000 3736 3959 518 4638 4511 712 6235 511 1166 1399 131 7599 753 704 510 1426 1921 2548 510 1103 1520 510 1103 1036 510 1920 2360 1520 510 1103 6947 510 808 4316 2360 1040 510 2958 7305 2360 1040 721 7555 2989 6835 131 7032 2435 3636 899 2207 6432 517 5010 1000 3736 3959 518 4638 4511 712 6235 2399 7977 131 4633 1767 8132 2259 8024 5310 2229 8176 2259 2360 837 131 2277 679 5408 8024 7599 3926 2813 8024 818 2769 6121 8024 3175 6395 4633 1767 868 1501 131 517 5010 1000 3736 3959 518 1350 1071 6122 4495 868 1501 704 3152 1399 131 808 4316 1103 7471 3449 5001 7716 131 2277 4130 4396 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:label: 0 (id = 0)\n",
      "INFO:transformers.data.processors.glue:*** Example ***\n",
      "INFO:transformers.data.processors.glue:guid: test-5\n",
      "INFO:transformers.data.processors.glue:input_ids: 101 2590 6841 2590 6841 1333 3341 3221 702 6631 5277 1987 2971 8024 679 2703 1987 1987 2063 782 8024 4197 5445 1987 1987 1316 1599 3614 671 1300 5439 2360 102 2203 3143 4638 782 131 5905 2563 3322 8024 7794 3187 5406 4633 1767 868 1501 131 7357 2658 808 2595 1166 131 4511 3036 6206 131 5905 2590 6841 8024 3221 3418 2945 1874 7676 7198 5634 2207 6432 517 7795 6887 4862 2360 518 3121 5356 4638 1367 6163 1196 517 7357 2658 808 518 4638 6235 5682 511 2399 7977 131 8126 2259 6716 7770 131 9801 8341 7652 4028 131 6948 5246 3215 1071 800 1399 4917 131 2590 6841 8024 3946 5723 8024 7350 5723 1996 1996 131 3946 2658 4495 3189 131 8146 3299 8110 3189 2157 5292 131 1922 7345 5292 8020 1184 8021 510 1318 756 5292 8020 4385 8021 704 3152 1399 131 5905 2590 6841 721 7555 2989 6835 131 4510 6228 1196 517 7357 2658 808 518 4638 6235 5682 1962 1351 131 5905 3250 811 8024 7032 1119 1356 1356 131 3946 2123 6981 7509 131 7357 7239 7319 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.data.processors.glue:attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:transformers.data.processors.glue:label: 0 (id = 0)\n",
      "INFO:transformers.data.processors.glue:Writing example 10000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 20000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 30000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 40000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 50000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 60000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 70000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 80000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 90000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 100000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 110000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 120000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 130000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 140000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 150000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 160000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 170000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 180000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 190000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 200000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 210000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 220000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 230000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 240000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 250000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 260000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 270000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 280000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 290000/309442\n",
      "INFO:transformers.data.processors.glue:Writing example 300000/309442\n"
     ]
    }
   ],
   "source": [
    "pretrained_path = '/media/bnu/data/transformers-pretrained-model/chinese_roberta_wwm_ext_pytorch/'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_path)\n",
    "\n",
    "train_loader = create_dataloader(\n",
    "    examples=train_examples,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=384,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    "    num_workers=6\n",
    ")\n",
    "\n",
    "valid_loader = create_dataloader(\n",
    "    examples=valid_examples,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=384,\n",
    "    shuffle=False,\n",
    "    batch_size=32,\n",
    "    num_workers=6\n",
    ")\n",
    "\n",
    "test_loader = create_dataloader(\n",
    "    examples=test_examples,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=384,\n",
    "    shuffle=False,\n",
    "    batch_size=32,\n",
    "    num_workers=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityLinkingModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(EntityLinkingModel, self).__init__()\n",
    "\n",
    "        config = BertConfig.from_json_file(pretrained_path+'/bert_config.json')\n",
    "        config.num_labels = 1\n",
    "        \n",
    "        # 预训练模型\n",
    "        self.bert = BertForSequenceClassification.from_pretrained(\n",
    "            pretrained_path+'/pytorch_model.bin',\n",
    "            config=config,\n",
    "        )\n",
    "\n",
    "        # 二分类损失函数\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        logits = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )[0]\n",
    "        return logits.squeeze()\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, token_type_ids, labels = batch\n",
    "        logits = self(input_ids, attention_mask, token_type_ids)\n",
    "        loss = self.criterion(logits, labels.float())\n",
    "\n",
    "        preds = (logits > 0).int() \n",
    "        acc = (preds == labels).float().mean()\n",
    "\n",
    "        tensorboard_logs = {'train_loss': loss, 'train_acc': acc}\n",
    "        return {'loss': loss, 'log': tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, token_type_ids, labels = batch\n",
    "        logits = self(input_ids, attention_mask, token_type_ids)\n",
    "        loss = self.criterion(logits, labels.float())\n",
    "\n",
    "        preds = (logits > 0).int() \n",
    "        acc = (preds == labels).float().mean()\n",
    "\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        val_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        val_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "\n",
    "        tensorboard_logs = {'val_loss': val_loss, 'val_acc': val_acc}\n",
    "        return {'val_loss': val_loss, 'log': tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=2e-5, eps=1e-8)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.modeling_utils:loading weights file /media/bnu/data/transformers-pretrained-model/chinese_roberta_wwm_ext_pytorch//pytorch_model.bin\n",
      "INFO:transformers.modeling_utils:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:VISIBLE GPUS: 0,1\n",
      "INFO:lightning:\n",
      "    | Name                                                  | Type                          | Params\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0   | bert                                                  | BertForSequenceClassification | 102 M \n",
      "1   | bert.bert                                             | BertModel                     | 102 M \n",
      "2   | bert.bert.embeddings                                  | BertEmbeddings                | 16 M  \n",
      "3   | bert.bert.embeddings.word_embeddings                  | Embedding                     | 16 M  \n",
      "4   | bert.bert.embeddings.position_embeddings              | Embedding                     | 393 K \n",
      "5   | bert.bert.embeddings.token_type_embeddings            | Embedding                     | 1 K   \n",
      "6   | bert.bert.embeddings.LayerNorm                        | LayerNorm                     | 1 K   \n",
      "7   | bert.bert.embeddings.dropout                          | Dropout                       | 0     \n",
      "8   | bert.bert.encoder                                     | BertEncoder                   | 85 M  \n",
      "9   | bert.bert.encoder.layer                               | ModuleList                    | 85 M  \n",
      "10  | bert.bert.encoder.layer.0                             | BertLayer                     | 7 M   \n",
      "11  | bert.bert.encoder.layer.0.attention                   | BertAttention                 | 2 M   \n",
      "12  | bert.bert.encoder.layer.0.attention.self              | BertSelfAttention             | 1 M   \n",
      "13  | bert.bert.encoder.layer.0.attention.self.query        | Linear                        | 590 K \n",
      "14  | bert.bert.encoder.layer.0.attention.self.key          | Linear                        | 590 K \n",
      "15  | bert.bert.encoder.layer.0.attention.self.value        | Linear                        | 590 K \n",
      "16  | bert.bert.encoder.layer.0.attention.self.dropout      | Dropout                       | 0     \n",
      "17  | bert.bert.encoder.layer.0.attention.output            | BertSelfOutput                | 592 K \n",
      "18  | bert.bert.encoder.layer.0.attention.output.dense      | Linear                        | 590 K \n",
      "19  | bert.bert.encoder.layer.0.attention.output.LayerNorm  | LayerNorm                     | 1 K   \n",
      "20  | bert.bert.encoder.layer.0.attention.output.dropout    | Dropout                       | 0     \n",
      "21  | bert.bert.encoder.layer.0.intermediate                | BertIntermediate              | 2 M   \n",
      "22  | bert.bert.encoder.layer.0.intermediate.dense          | Linear                        | 2 M   \n",
      "23  | bert.bert.encoder.layer.0.output                      | BertOutput                    | 2 M   \n",
      "24  | bert.bert.encoder.layer.0.output.dense                | Linear                        | 2 M   \n",
      "25  | bert.bert.encoder.layer.0.output.LayerNorm            | LayerNorm                     | 1 K   \n",
      "26  | bert.bert.encoder.layer.0.output.dropout              | Dropout                       | 0     \n",
      "27  | bert.bert.encoder.layer.1                             | BertLayer                     | 7 M   \n",
      "28  | bert.bert.encoder.layer.1.attention                   | BertAttention                 | 2 M   \n",
      "29  | bert.bert.encoder.layer.1.attention.self              | BertSelfAttention             | 1 M   \n",
      "30  | bert.bert.encoder.layer.1.attention.self.query        | Linear                        | 590 K \n",
      "31  | bert.bert.encoder.layer.1.attention.self.key          | Linear                        | 590 K \n",
      "32  | bert.bert.encoder.layer.1.attention.self.value        | Linear                        | 590 K \n",
      "33  | bert.bert.encoder.layer.1.attention.self.dropout      | Dropout                       | 0     \n",
      "34  | bert.bert.encoder.layer.1.attention.output            | BertSelfOutput                | 592 K \n",
      "35  | bert.bert.encoder.layer.1.attention.output.dense      | Linear                        | 590 K \n",
      "36  | bert.bert.encoder.layer.1.attention.output.LayerNorm  | LayerNorm                     | 1 K   \n",
      "37  | bert.bert.encoder.layer.1.attention.output.dropout    | Dropout                       | 0     \n",
      "38  | bert.bert.encoder.layer.1.intermediate                | BertIntermediate              | 2 M   \n",
      "39  | bert.bert.encoder.layer.1.intermediate.dense          | Linear                        | 2 M   \n",
      "40  | bert.bert.encoder.layer.1.output                      | BertOutput                    | 2 M   \n",
      "41  | bert.bert.encoder.layer.1.output.dense                | Linear                        | 2 M   \n",
      "42  | bert.bert.encoder.layer.1.output.LayerNorm            | LayerNorm                     | 1 K   \n",
      "43  | bert.bert.encoder.layer.1.output.dropout              | Dropout                       | 0     \n",
      "44  | bert.bert.encoder.layer.2                             | BertLayer                     | 7 M   \n",
      "45  | bert.bert.encoder.layer.2.attention                   | BertAttention                 | 2 M   \n",
      "46  | bert.bert.encoder.layer.2.attention.self              | BertSelfAttention             | 1 M   \n",
      "47  | bert.bert.encoder.layer.2.attention.self.query        | Linear                        | 590 K \n",
      "48  | bert.bert.encoder.layer.2.attention.self.key          | Linear                        | 590 K \n",
      "49  | bert.bert.encoder.layer.2.attention.self.value        | Linear                        | 590 K \n",
      "50  | bert.bert.encoder.layer.2.attention.self.dropout      | Dropout                       | 0     \n",
      "51  | bert.bert.encoder.layer.2.attention.output            | BertSelfOutput                | 592 K \n",
      "52  | bert.bert.encoder.layer.2.attention.output.dense      | Linear                        | 590 K \n",
      "53  | bert.bert.encoder.layer.2.attention.output.LayerNorm  | LayerNorm                     | 1 K   \n",
      "54  | bert.bert.encoder.layer.2.attention.output.dropout    | Dropout                       | 0     \n",
      "55  | bert.bert.encoder.layer.2.intermediate                | BertIntermediate              | 2 M   \n",
      "56  | bert.bert.encoder.layer.2.intermediate.dense          | Linear                        | 2 M   \n",
      "57  | bert.bert.encoder.layer.2.output                      | BertOutput                    | 2 M   \n",
      "58  | bert.bert.encoder.layer.2.output.dense                | Linear                        | 2 M   \n",
      "59  | bert.bert.encoder.layer.2.output.LayerNorm            | LayerNorm                     | 1 K   \n",
      "60  | bert.bert.encoder.layer.2.output.dropout              | Dropout                       | 0     \n",
      "61  | bert.bert.encoder.layer.3                             | BertLayer                     | 7 M   \n",
      "62  | bert.bert.encoder.layer.3.attention                   | BertAttention                 | 2 M   \n",
      "63  | bert.bert.encoder.layer.3.attention.self              | BertSelfAttention             | 1 M   \n",
      "64  | bert.bert.encoder.layer.3.attention.self.query        | Linear                        | 590 K \n",
      "65  | bert.bert.encoder.layer.3.attention.self.key          | Linear                        | 590 K \n",
      "66  | bert.bert.encoder.layer.3.attention.self.value        | Linear                        | 590 K \n",
      "67  | bert.bert.encoder.layer.3.attention.self.dropout      | Dropout                       | 0     \n",
      "68  | bert.bert.encoder.layer.3.attention.output            | BertSelfOutput                | 592 K \n",
      "69  | bert.bert.encoder.layer.3.attention.output.dense      | Linear                        | 590 K \n",
      "70  | bert.bert.encoder.layer.3.attention.output.LayerNorm  | LayerNorm                     | 1 K   \n",
      "71  | bert.bert.encoder.layer.3.attention.output.dropout    | Dropout                       | 0     \n",
      "72  | bert.bert.encoder.layer.3.intermediate                | BertIntermediate              | 2 M   \n",
      "73  | bert.bert.encoder.layer.3.intermediate.dense          | Linear                        | 2 M   \n",
      "74  | bert.bert.encoder.layer.3.output                      | BertOutput                    | 2 M   \n",
      "75  | bert.bert.encoder.layer.3.output.dense                | Linear                        | 2 M   \n",
      "76  | bert.bert.encoder.layer.3.output.LayerNorm            | LayerNorm                     | 1 K   \n",
      "77  | bert.bert.encoder.layer.3.output.dropout              | Dropout                       | 0     \n",
      "78  | bert.bert.encoder.layer.4                             | BertLayer                     | 7 M   \n",
      "79  | bert.bert.encoder.layer.4.attention                   | BertAttention                 | 2 M   \n",
      "80  | bert.bert.encoder.layer.4.attention.self              | BertSelfAttention             | 1 M   \n",
      "81  | bert.bert.encoder.layer.4.attention.self.query        | Linear                        | 590 K \n",
      "82  | bert.bert.encoder.layer.4.attention.self.key          | Linear                        | 590 K \n",
      "83  | bert.bert.encoder.layer.4.attention.self.value        | Linear                        | 590 K \n",
      "84  | bert.bert.encoder.layer.4.attention.self.dropout      | Dropout                       | 0     \n",
      "85  | bert.bert.encoder.layer.4.attention.output            | BertSelfOutput                | 592 K \n",
      "86  | bert.bert.encoder.layer.4.attention.output.dense      | Linear                        | 590 K \n",
      "87  | bert.bert.encoder.layer.4.attention.output.LayerNorm  | LayerNorm                     | 1 K   \n",
      "88  | bert.bert.encoder.layer.4.attention.output.dropout    | Dropout                       | 0     \n",
      "89  | bert.bert.encoder.layer.4.intermediate                | BertIntermediate              | 2 M   \n",
      "90  | bert.bert.encoder.layer.4.intermediate.dense          | Linear                        | 2 M   \n",
      "91  | bert.bert.encoder.layer.4.output                      | BertOutput                    | 2 M   \n",
      "92  | bert.bert.encoder.layer.4.output.dense                | Linear                        | 2 M   \n",
      "93  | bert.bert.encoder.layer.4.output.LayerNorm            | LayerNorm                     | 1 K   \n",
      "94  | bert.bert.encoder.layer.4.output.dropout              | Dropout                       | 0     \n",
      "95  | bert.bert.encoder.layer.5                             | BertLayer                     | 7 M   \n",
      "96  | bert.bert.encoder.layer.5.attention                   | BertAttention                 | 2 M   \n",
      "97  | bert.bert.encoder.layer.5.attention.self              | BertSelfAttention             | 1 M   \n",
      "98  | bert.bert.encoder.layer.5.attention.self.query        | Linear                        | 590 K \n",
      "99  | bert.bert.encoder.layer.5.attention.self.key          | Linear                        | 590 K \n",
      "100 | bert.bert.encoder.layer.5.attention.self.value        | Linear                        | 590 K \n",
      "101 | bert.bert.encoder.layer.5.attention.self.dropout      | Dropout                       | 0     \n",
      "102 | bert.bert.encoder.layer.5.attention.output            | BertSelfOutput                | 592 K \n",
      "103 | bert.bert.encoder.layer.5.attention.output.dense      | Linear                        | 590 K \n",
      "104 | bert.bert.encoder.layer.5.attention.output.LayerNorm  | LayerNorm                     | 1 K   \n",
      "105 | bert.bert.encoder.layer.5.attention.output.dropout    | Dropout                       | 0     \n",
      "106 | bert.bert.encoder.layer.5.intermediate                | BertIntermediate              | 2 M   \n",
      "107 | bert.bert.encoder.layer.5.intermediate.dense          | Linear                        | 2 M   \n",
      "108 | bert.bert.encoder.layer.5.output                      | BertOutput                    | 2 M   \n",
      "109 | bert.bert.encoder.layer.5.output.dense                | Linear                        | 2 M   \n",
      "110 | bert.bert.encoder.layer.5.output.LayerNorm            | LayerNorm                     | 1 K   \n",
      "111 | bert.bert.encoder.layer.5.output.dropout              | Dropout                       | 0     \n",
      "112 | bert.bert.encoder.layer.6                             | BertLayer                     | 7 M   \n",
      "113 | bert.bert.encoder.layer.6.attention                   | BertAttention                 | 2 M   \n",
      "114 | bert.bert.encoder.layer.6.attention.self              | BertSelfAttention             | 1 M   \n",
      "115 | bert.bert.encoder.layer.6.attention.self.query        | Linear                        | 590 K \n",
      "116 | bert.bert.encoder.layer.6.attention.self.key          | Linear                        | 590 K \n",
      "117 | bert.bert.encoder.layer.6.attention.self.value        | Linear                        | 590 K \n",
      "118 | bert.bert.encoder.layer.6.attention.self.dropout      | Dropout                       | 0     \n",
      "119 | bert.bert.encoder.layer.6.attention.output            | BertSelfOutput                | 592 K \n",
      "120 | bert.bert.encoder.layer.6.attention.output.dense      | Linear                        | 590 K \n",
      "121 | bert.bert.encoder.layer.6.attention.output.LayerNorm  | LayerNorm                     | 1 K   \n",
      "122 | bert.bert.encoder.layer.6.attention.output.dropout    | Dropout                       | 0     \n",
      "123 | bert.bert.encoder.layer.6.intermediate                | BertIntermediate              | 2 M   \n",
      "124 | bert.bert.encoder.layer.6.intermediate.dense          | Linear                        | 2 M   \n",
      "125 | bert.bert.encoder.layer.6.output                      | BertOutput                    | 2 M   \n",
      "126 | bert.bert.encoder.layer.6.output.dense                | Linear                        | 2 M   \n",
      "127 | bert.bert.encoder.layer.6.output.LayerNorm            | LayerNorm                     | 1 K   \n",
      "128 | bert.bert.encoder.layer.6.output.dropout              | Dropout                       | 0     \n",
      "129 | bert.bert.encoder.layer.7                             | BertLayer                     | 7 M   \n",
      "130 | bert.bert.encoder.layer.7.attention                   | BertAttention                 | 2 M   \n",
      "131 | bert.bert.encoder.layer.7.attention.self              | BertSelfAttention             | 1 M   \n",
      "132 | bert.bert.encoder.layer.7.attention.self.query        | Linear                        | 590 K \n",
      "133 | bert.bert.encoder.layer.7.attention.self.key          | Linear                        | 590 K \n",
      "134 | bert.bert.encoder.layer.7.attention.self.value        | Linear                        | 590 K \n",
      "135 | bert.bert.encoder.layer.7.attention.self.dropout      | Dropout                       | 0     \n",
      "136 | bert.bert.encoder.layer.7.attention.output            | BertSelfOutput                | 592 K \n",
      "137 | bert.bert.encoder.layer.7.attention.output.dense      | Linear                        | 590 K \n",
      "138 | bert.bert.encoder.layer.7.attention.output.LayerNorm  | LayerNorm                     | 1 K   \n",
      "139 | bert.bert.encoder.layer.7.attention.output.dropout    | Dropout                       | 0     \n",
      "140 | bert.bert.encoder.layer.7.intermediate                | BertIntermediate              | 2 M   \n",
      "141 | bert.bert.encoder.layer.7.intermediate.dense          | Linear                        | 2 M   \n",
      "142 | bert.bert.encoder.layer.7.output                      | BertOutput                    | 2 M   \n",
      "143 | bert.bert.encoder.layer.7.output.dense                | Linear                        | 2 M   \n",
      "144 | bert.bert.encoder.layer.7.output.LayerNorm            | LayerNorm                     | 1 K   \n",
      "145 | bert.bert.encoder.layer.7.output.dropout              | Dropout                       | 0     \n",
      "146 | bert.bert.encoder.layer.8                             | BertLayer                     | 7 M   \n",
      "147 | bert.bert.encoder.layer.8.attention                   | BertAttention                 | 2 M   \n",
      "148 | bert.bert.encoder.layer.8.attention.self              | BertSelfAttention             | 1 M   \n",
      "149 | bert.bert.encoder.layer.8.attention.self.query        | Linear                        | 590 K \n",
      "150 | bert.bert.encoder.layer.8.attention.self.key          | Linear                        | 590 K \n",
      "151 | bert.bert.encoder.layer.8.attention.self.value        | Linear                        | 590 K \n",
      "152 | bert.bert.encoder.layer.8.attention.self.dropout      | Dropout                       | 0     \n",
      "153 | bert.bert.encoder.layer.8.attention.output            | BertSelfOutput                | 592 K \n",
      "154 | bert.bert.encoder.layer.8.attention.output.dense      | Linear                        | 590 K \n",
      "155 | bert.bert.encoder.layer.8.attention.output.LayerNorm  | LayerNorm                     | 1 K   \n",
      "156 | bert.bert.encoder.layer.8.attention.output.dropout    | Dropout                       | 0     \n",
      "157 | bert.bert.encoder.layer.8.intermediate                | BertIntermediate              | 2 M   \n",
      "158 | bert.bert.encoder.layer.8.intermediate.dense          | Linear                        | 2 M   \n",
      "159 | bert.bert.encoder.layer.8.output                      | BertOutput                    | 2 M   \n",
      "160 | bert.bert.encoder.layer.8.output.dense                | Linear                        | 2 M   \n",
      "161 | bert.bert.encoder.layer.8.output.LayerNorm            | LayerNorm                     | 1 K   \n",
      "162 | bert.bert.encoder.layer.8.output.dropout              | Dropout                       | 0     \n",
      "163 | bert.bert.encoder.layer.9                             | BertLayer                     | 7 M   \n",
      "164 | bert.bert.encoder.layer.9.attention                   | BertAttention                 | 2 M   \n",
      "165 | bert.bert.encoder.layer.9.attention.self              | BertSelfAttention             | 1 M   \n",
      "166 | bert.bert.encoder.layer.9.attention.self.query        | Linear                        | 590 K \n",
      "167 | bert.bert.encoder.layer.9.attention.self.key          | Linear                        | 590 K \n",
      "168 | bert.bert.encoder.layer.9.attention.self.value        | Linear                        | 590 K \n",
      "169 | bert.bert.encoder.layer.9.attention.self.dropout      | Dropout                       | 0     \n",
      "170 | bert.bert.encoder.layer.9.attention.output            | BertSelfOutput                | 592 K \n",
      "171 | bert.bert.encoder.layer.9.attention.output.dense      | Linear                        | 590 K \n",
      "172 | bert.bert.encoder.layer.9.attention.output.LayerNorm  | LayerNorm                     | 1 K   \n",
      "173 | bert.bert.encoder.layer.9.attention.output.dropout    | Dropout                       | 0     \n",
      "174 | bert.bert.encoder.layer.9.intermediate                | BertIntermediate              | 2 M   \n",
      "175 | bert.bert.encoder.layer.9.intermediate.dense          | Linear                        | 2 M   \n",
      "176 | bert.bert.encoder.layer.9.output                      | BertOutput                    | 2 M   \n",
      "177 | bert.bert.encoder.layer.9.output.dense                | Linear                        | 2 M   \n",
      "178 | bert.bert.encoder.layer.9.output.LayerNorm            | LayerNorm                     | 1 K   \n",
      "179 | bert.bert.encoder.layer.9.output.dropout              | Dropout                       | 0     \n",
      "180 | bert.bert.encoder.layer.10                            | BertLayer                     | 7 M   \n",
      "181 | bert.bert.encoder.layer.10.attention                  | BertAttention                 | 2 M   \n",
      "182 | bert.bert.encoder.layer.10.attention.self             | BertSelfAttention             | 1 M   \n",
      "183 | bert.bert.encoder.layer.10.attention.self.query       | Linear                        | 590 K \n",
      "184 | bert.bert.encoder.layer.10.attention.self.key         | Linear                        | 590 K \n",
      "185 | bert.bert.encoder.layer.10.attention.self.value       | Linear                        | 590 K \n",
      "186 | bert.bert.encoder.layer.10.attention.self.dropout     | Dropout                       | 0     \n",
      "187 | bert.bert.encoder.layer.10.attention.output           | BertSelfOutput                | 592 K \n",
      "188 | bert.bert.encoder.layer.10.attention.output.dense     | Linear                        | 590 K \n",
      "189 | bert.bert.encoder.layer.10.attention.output.LayerNorm | LayerNorm                     | 1 K   \n",
      "190 | bert.bert.encoder.layer.10.attention.output.dropout   | Dropout                       | 0     \n",
      "191 | bert.bert.encoder.layer.10.intermediate               | BertIntermediate              | 2 M   \n",
      "192 | bert.bert.encoder.layer.10.intermediate.dense         | Linear                        | 2 M   \n",
      "193 | bert.bert.encoder.layer.10.output                     | BertOutput                    | 2 M   \n",
      "194 | bert.bert.encoder.layer.10.output.dense               | Linear                        | 2 M   \n",
      "195 | bert.bert.encoder.layer.10.output.LayerNorm           | LayerNorm                     | 1 K   \n",
      "196 | bert.bert.encoder.layer.10.output.dropout             | Dropout                       | 0     \n",
      "197 | bert.bert.encoder.layer.11                            | BertLayer                     | 7 M   \n",
      "198 | bert.bert.encoder.layer.11.attention                  | BertAttention                 | 2 M   \n",
      "199 | bert.bert.encoder.layer.11.attention.self             | BertSelfAttention             | 1 M   \n",
      "200 | bert.bert.encoder.layer.11.attention.self.query       | Linear                        | 590 K \n",
      "201 | bert.bert.encoder.layer.11.attention.self.key         | Linear                        | 590 K \n",
      "202 | bert.bert.encoder.layer.11.attention.self.value       | Linear                        | 590 K \n",
      "203 | bert.bert.encoder.layer.11.attention.self.dropout     | Dropout                       | 0     \n",
      "204 | bert.bert.encoder.layer.11.attention.output           | BertSelfOutput                | 592 K \n",
      "205 | bert.bert.encoder.layer.11.attention.output.dense     | Linear                        | 590 K \n",
      "206 | bert.bert.encoder.layer.11.attention.output.LayerNorm | LayerNorm                     | 1 K   \n",
      "207 | bert.bert.encoder.layer.11.attention.output.dropout   | Dropout                       | 0     \n",
      "208 | bert.bert.encoder.layer.11.intermediate               | BertIntermediate              | 2 M   \n",
      "209 | bert.bert.encoder.layer.11.intermediate.dense         | Linear                        | 2 M   \n",
      "210 | bert.bert.encoder.layer.11.output                     | BertOutput                    | 2 M   \n",
      "211 | bert.bert.encoder.layer.11.output.dense               | Linear                        | 2 M   \n",
      "212 | bert.bert.encoder.layer.11.output.LayerNorm           | LayerNorm                     | 1 K   \n",
      "213 | bert.bert.encoder.layer.11.output.dropout             | Dropout                       | 0     \n",
      "214 | bert.bert.pooler                                      | BertPooler                    | 590 K \n",
      "215 | bert.bert.pooler.dense                                | Linear                        | 590 K \n",
      "216 | bert.bert.pooler.activation                           | Tanh                          | 0     \n",
      "217 | bert.dropout                                          | Dropout                       | 0     \n",
      "218 | bert.classifier                                       | Linear                        | 769   \n",
      "219 | criterion                                             | BCEWithLogitsLoss             | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e900c425780e47b1a349d979a72877b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 10.76 GiB total capacity; 9.35 GiB already allocated; 21.69 MiB free; 9.52 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a9f38395b749>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, test_dataloaders)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;31m# easier to avoid NCCL issues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_dp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdp_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_parts.py\u001b[0m in \u001b[0;36mdp_train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLightningDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0;31m# RUN TNG EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;31m# update LR schedulers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;31m# RUN TRAIN STEP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;31m# ---------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0m_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0mbatch_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_step_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;31m# detach tensors in batch_output before appending to outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;31m# check if loss or model weights are nan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    570\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_forward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                         output_dict = self.training_forward(\n\u001b[0;32m--> 572\u001b[0;31m                             split_batch, batch_idx, opt_idx, self.hiddens)\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                         \u001b[0;31m# format and reduce outputs accordingly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_forward\u001b[0;34m(self, batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;31m# distributed forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_ddp\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_ddp2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_dp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;31m# single GPU forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/pytorch_lightning/overrides/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/pytorch_lightning/overrides/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/pytorch_lightning/overrides/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/pytorch_lightning/overrides/data_parallel.py\u001b[0m in \u001b[0;36m_worker\u001b[0;34m(i, module, input, kwargs, device)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;31m# CHANGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-650f6c51f727>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-650f6c51f727>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         )[0]\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m   1174\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m         )\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         )\n\u001b[1;32m    792\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m             )\n\u001b[1;32m    409\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     ):\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mself_attention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add self attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    312\u001b[0m     ):\n\u001b[1;32m    313\u001b[0m         self_outputs = self.self(\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         )\n\u001b[1;32m    316\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_probs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 10.76 GiB total capacity; 9.35 GiB already allocated; 21.69 MiB free; 9.52 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model = EntityLinkingModel()\n",
    "save_path = '/media/bnu/data/pytorch-lightning-checkpoints/EntityLinking/'\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    filepath=save_path,\n",
    "    save_top_k=True,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    prefix='EL_',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "#     val_check_interval=0.1,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "#     gpus=1,\n",
    "    gpus=2,\n",
    "    distributed_backend='dp',\n",
    "    default_save_path=save_path,\n",
    "    profiler=True,\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.modeling_utils:loading weights file /media/bnu/data/transformers-pretrained-model/chinese_roberta_wwm_ext_pytorch//pytorch_model.bin\n",
      "INFO:transformers.modeling_utils:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7366, 0.8043, 0.5222, 0.5221, 0.8672, 0.6929, 0.5325, 0.6781, 0.3220,\n",
      "        0.4888, 0.5010, 0.2940, 0.4860, 0.5321, 0.5085, 0.5989, 0.5111, 0.5920,\n",
      "        0.5531, 0.6092, 0.6262, 0.6959, 0.4237, 0.7809, 0.4985, 0.7876, 0.7559,\n",
      "        0.5531, 0.5516, 0.8327, 0.6327, 0.6183])\n"
     ]
    }
   ],
   "source": [
    "model = EntityLinkingModel()\n",
    "for batch in valid_loader:\n",
    "    input_ids, attention_mask, token_type_ids, labels = batch\n",
    "    logits = model(input_ids, attention_mask, token_type_ids)\n",
    "    print(logits)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = Path('/home/bnu/projects/CCKS2020-Entity-Linking/ckpt/')\n",
    "trainer.save_checkpoint(ckpt_path/'EL-RoBERTa-128-0419.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file /media/bnu/data/transformers-pretrained-model/chinese_roberta_wwm_ext_pytorch/bert_config.json\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file /media/bnu/data/transformers-pretrained-model/chinese_roberta_wwm_ext_pytorch/pytorch_model.bin\n",
      "INFO:transformers.modeling_utils:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([6.3753e-03, 5.0309e-04, 4.3646e-04, 9.7265e-01, 9.9619e-01, 3.3942e-02,\n",
       "        9.9538e-01, 7.3173e-01, 9.9759e-01, 9.9883e-01, 2.1060e-03, 9.8735e-01,\n",
       "        3.8978e-04, 2.0384e-01, 9.5879e-01, 2.9894e-03, 1.2333e-02, 7.7380e-01,\n",
       "        4.1989e-04, 1.2595e-01, 4.8184e-04, 9.7496e-01, 8.5529e-01, 1.4261e-03,\n",
       "        4.5359e-04, 1.0327e-01, 4.1051e-04, 2.2023e-01, 1.5070e-02, 9.6544e-01,\n",
       "        4.5117e-04, 4.6139e-03])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ELRoBERTaModel.load_from_checkpoint(\n",
    "    ckpt_path/'EL-RoBERTa-128-0419.ckpt',\n",
    "    pretrained_path=pretrained_path,\n",
    "    train_loader=None,\n",
    "    valid_loader=None,\n",
    ")\n",
    "model.eval()\n",
    "batch = next(iter(valid_loader))\n",
    "outputs = model(batch[0], batch[1], batch[2])\n",
    "F.softmax(outputs, dim=-1)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
