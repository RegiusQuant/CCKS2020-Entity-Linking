{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import pytorch_lightning as pl\n",
    "from transformers import (\n",
    "    DataProcessor,\n",
    "    InputExample,\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    BertConfig,\n",
    "    glue_convert_examples_to_features,\n",
    ")\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_random_seed(2020)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "data_path = \"../../data/ccks2020_el_data_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCKS 2020 Entity Linking License.docx  EL_FEATURE_VALID.pkl  train.json\r\n",
      "dev.json\t\t\t       eval.py\t\t     train_link_all.tsv\r\n",
      "dev_link_all.tsv\t\t       id_to_type.txt\t     train_link.tsv\r\n",
      "dev_link.tsv\t\t\t       kb.json\t\t     train_type.csv\r\n",
      "dev_type.csv\t\t\t       README\r\n",
      "EL_FEATURE_TRAIN.pkl\t\t       test.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls $data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity\toffset\trawtext\tkbtext\tpredict\r\n",
      "天下没有不散的宴席\t0\t天下没有不散的宴席 - ╰つ雲中帆╰つ\t摘要:《项羽·本纪》是有这个意思，但“天下无有不散筵席”是翻译后的话，不是原文的出处。 义项描述:天下没有不散的宴席 含义:团聚是相对的，终究要分离的。 中文名:天下没有不散的宴席 拼音:tiān xià wú bù sàn yán xí 标签:文化\t1\r\n",
      "永嘉\t0\t永嘉厂房出租\t出生地:永嘉（今温州） 外文名:Always fine 摘要:永嘉禅师（公元665年——713年），永嘉（今温州）人，是六祖惠能的法嗣，禅宗称之为“第三十四代真觉禅师”，法名玄觉，号明道。 代表作品:《永嘉证道歌》 逝世日期:公元713年 中文名:永嘉 信仰:佛教 义项描述:唐朝时期僧侣 国籍:中国 出生日期:公元665年 职业:僧人 民族:汉族 标签:人物\t0\r\n",
      "永嘉\t0\t永嘉厂房出租\t摘要:永嘉也用作年号，历史上用过两次。 义项描述:帝王年号 朝代:西晋、大理 中文名:永嘉 性质:帝王年号 标签:历史\t0\r\n",
      "永嘉\t0\t永嘉厂房出租\t所属地区:中国华东 地理位置:浙江省南部，温州市北部，瓯江下游 友好城市:剑阁县 黟县 霍邱县 车牌代码:浙C 行政代码:330324 地标:防洪水闸工程 机场:温州龙湾国际机场 气候条件:亚热带季风气候 知名企业:宣达集团 超达 报喜鸟 奥康 火车站:永嘉火车站 别称:瓯 行政区类别:县 下辖地区:7街道11镇4乡 摘要:永嘉县，中国浙江省温州市下辖的一个县，位于浙江省东南部，瓯江下游北岸，东邻乐清、黄岩，西连青田、缙云，北接仙居，南与温州市区隔江相望。 电话区号:0577 面积:2698平方公里 别名:永宁 人口:82.69万（2016年常住人口） 中文名称:永嘉县 特产:西瓜罗坑梅 碧莲香柚 永嘉麦饼 著名景点:楠溪江，四海山 县委书记:王彩莲 方言:吴语-温州话 邮政区码:325100 外文名称:Yong Jia County 义项描述:浙江省温州市下辖县 政府驻地:上塘中心城区北城街道县前路94号\t1\r\n",
      "厂房\t2\t永嘉厂房出租\t摘要:工业厂房，指直接用于生产或为生产配套的各种房屋，包括主要车间、辅助用房及附属设施用房。 印花税:总价的0.05%； 义项描述:工业厂房 中文名:工业厂房 登记费:300元/件； 契税:总价的3%； 标签:社会、生活\t1\r\n",
      "厂房\t2\t永嘉厂房出租\t摘要:无隔墙的房屋。 拼音:chǎng fáng 出处:《官场现形记》 注音:ㄔㄤˇ ㄈㄤˊ 中文名:厂房 义项描述:厂房 标签:文化\t0\r\n",
      "出租\t4\t永嘉厂房出租\t外文名:rental 摘要:动词，收取一定的代价，让别人在约定期限内使用。 拼音:chū zū 解释:交纳租税 中文名:出租 举例:出租图书 日本語:レンタル 义项描述:出租 标签:非娱乐作品、娱乐作品、小说作品、语言、电影、字词\t1\r\n",
      "出租\t4\t永嘉厂房出租\t外文名:Taxi、Cab、Hackies 摘要:出租车，供人临时雇佣的汽车，多按里程或时间收费，也叫出租车。 粤语:的士 台湾名:计程车 拼音:chūzūchē 中文名:出租车 义项描述:辞源释义 新加坡名:德士 标签:交通工具、社会、生活\t0\r\n",
      "我是猫\t1\t《我是猫》([日]夏目漱石)【摘要 书评 试读】\t歌曲原唱:古巨基 歌曲时长:3:22 歌曲语言:中文 音乐风格:小清新 摘要:一首歌手古巨基唱的歌，主题为我是猫。 所属专辑:大雄 外文名称:I'm a cat 中文名称:我是猫 义项描述:古巨基演唱歌曲 MV导演:大雄 标签:流行音乐、单曲、音乐作品\t0\r\n"
     ]
    }
   ],
   "source": [
    "!head $data_path/dev_link.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>offset</th>\n",
       "      <th>rawtext</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>小品</td>\n",
       "      <td>0</td>\n",
       "      <td>小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>战狼故事</td>\n",
       "      <td>3</td>\n",
       "      <td>小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人</td>\n",
       "      <td>Work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>吴京</td>\n",
       "      <td>10</td>\n",
       "      <td>小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人</td>\n",
       "      <td>Person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>障碍</td>\n",
       "      <td>16</td>\n",
       "      <td>小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>爱人</td>\n",
       "      <td>20</td>\n",
       "      <td>小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity  offset                         rawtext    type\n",
       "0     小品       0  小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人   Other\n",
       "1   战狼故事       3  小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人    Work\n",
       "2     吴京      10  小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人  Person\n",
       "3     障碍      16  小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人   Other\n",
       "4     爱人      20  小品《战狼故事》中，吴京突破重重障碍解救爱人，深情告白太感人   Other"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(os.path.join(data_path, 'train_type.csv'), sep='\\t')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_type = []\n",
    "with open(os.path.join(data_path, \"id_to_type.txt\")) as fin:\n",
    "    for line in fin:\n",
    "        idx_to_type.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Person',\n",
       " 'Work',\n",
       " 'Medicine',\n",
       " 'Game',\n",
       " 'Other',\n",
       " 'Organization',\n",
       " 'Location',\n",
       " 'Culture',\n",
       " 'Biological',\n",
       " 'VirtualThings',\n",
       " 'Natural&Geography',\n",
       " 'Website',\n",
       " 'Event',\n",
       " 'Brand',\n",
       " 'Food',\n",
       " 'Awards',\n",
       " 'Time&Calendar',\n",
       " 'Disease&Symptom',\n",
       " 'Software',\n",
       " 'Vehicle',\n",
       " 'Education',\n",
       " 'Constellation',\n",
       " 'Diagnosis&Treatment',\n",
       " 'Law&Regulation']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们首先创建一个DataProcessor，这个processor需要能够加载train和dev的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETProcessor(DataProcessor):\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, 'train_type.csv')),\n",
    "            set_type='train',\n",
    "        )\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, 'dev_type.csv')),\n",
    "            set_type='valid',\n",
    "        )\n",
    "\n",
    "    def get_labels(self):\n",
    "        return idx_to_type\n",
    "\n",
    "    def _create_examples(self, lines, set_type):\n",
    "        examples = []\n",
    "        for i, line in enumerate(lines):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            guid = f'{set_type}-{i}'\n",
    "            try:\n",
    "                text_a = line[0]\n",
    "                text_b = line[2]\n",
    "                label = line[3]  \n",
    "                examples.append(InputExample(\n",
    "                    guid=guid,\n",
    "                    text_a=text_a,\n",
    "                    text_b=text_b,\n",
    "                    label=label,\n",
    "                ))\n",
    "            except:\n",
    "                print(i)\n",
    "                print(line)\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InputExample(guid='train-11', text_a='动作', text_b='甄嬛传：安陵容怀孕时，雍正经常摸她的肚子，原来这动作大有深意', label='Other')\n",
      "Train: 266740\n",
      "Dev: 33074\n"
     ]
    }
   ],
   "source": [
    "processor = ETProcessor()\n",
    "examples = processor.get_train_examples(data_path)\n",
    "print(examples[10])\n",
    "print('Train:', len(examples))\n",
    "examples = processor.get_dev_examples(data_path)\n",
    "print('Dev:', len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataloaders(tokenizer, data_path):\n",
    "    def generate_dataloader_inner(examples):\n",
    "        features = glue_convert_examples_to_features(\n",
    "            examples,\n",
    "            tokenizer,\n",
    "            label_list=idx_to_type,\n",
    "            max_length=64,\n",
    "            output_mode='classification',)\n",
    "\n",
    "        dataset = torch.utils.data.TensorDataset(\n",
    "            torch.LongTensor([f.input_ids for f in features]),\n",
    "            torch.LongTensor([f.attention_mask for f in features]),\n",
    "            torch.LongTensor([f.token_type_ids for f in features]),\n",
    "            torch.LongTensor([f.label for f in features])\n",
    "        )\n",
    "\n",
    "        sampler = torch.utils.data.RandomSampler(dataset)\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            dataset, sampler=sampler, batch_size=32\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    # 训练数据\n",
    "    train_examples = processor.get_train_examples(data_path)\n",
    "    print('Load Example Finish')\n",
    "    train_loader = generate_dataloader_inner(train_examples)\n",
    "    print('Generate DataLoader Finish')\n",
    "    \n",
    "    # 验证数据\n",
    "    valid_examples = processor.get_dev_examples(data_path)\n",
    "    print('Load Example Finish')\n",
    "    valid_loader = generate_dataloader_inner(valid_examples)\n",
    "    print('Generate DataLoader Finish')\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们要使用的模型都是基于BERT预训练模型的。同学们需要从以下链接下载需要的预训练模型。\n",
    "https://github.com/ymcui/Chinese-BERT-wwm\n",
    "\n",
    "注意：虽然其中的几个模型名称中包含roberta，但是实际上模型是基于BERT训练的，所以在使用transformer库加载的时候需要使用BERT模型加载。\n",
    "\n",
    "回顾：BERT和RoBERTa模型的区别是什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Example Finish\n",
      "Generate DataLoader Finish\n",
      "Load Example Finish\n",
      "Generate DataLoader Finish\n"
     ]
    }
   ],
   "source": [
    "roberta_path = \"../../../../../../../research/pretrained_models/chinese_roberta_wwm_large_ext_pytorch\"\n",
    "# 这里的roberta path需要按照实际情况修改成自己保存的roberta路径。\n",
    "tokenizer = BertTokenizer.from_pretrained(roberta_path)\n",
    "train_loader, valid_loader = generate_dataloaders(tokenizer, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们用PyTorch Lightning来定义我们的模型和训练框架。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETRoBERTaModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "                 pretrained_path, \n",
    "                 train_loader, \n",
    "                 valid_loader):\n",
    "        super(ETRoBERTaModel, self).__init__()\n",
    "        self.train_loader = train_loader\n",
    "        self.valid_loader = valid_loader\n",
    "\n",
    "        config = BertConfig.from_json_file(pretrained_path+'/config.json')\n",
    "        config.num_labels = len(idx_to_type)\n",
    "        print(config)\n",
    "        \n",
    "        # 预训练模型\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        self.ptm = BertForSequenceClassification.from_pretrained(\n",
    "            os.path.join(pretrained_path, 'pytorch_model.bin'),\n",
    "            config=config,\n",
    "        )\n",
    "\n",
    "        # 损失函数\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # 这里会回复模型预测的logits\n",
    "        return self.ptm(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )[0]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, token_type_ids, label = batch\n",
    "        out = self(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        loss = self.criterion(out, label)\n",
    "\n",
    "        _, pred = torch.max(out, dim=1)\n",
    "        acc = (pred == label).float().mean()\n",
    "\n",
    "        tensorboard_logs = {'train_loss': loss, 'train_acc': acc}\n",
    "        return {'loss': loss, 'log': tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, token_type_ids, label = batch\n",
    "        out = self(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        loss = self.criterion(out, label)\n",
    "\n",
    "        _, pred = torch.max(out, dim=1)\n",
    "        acc = (pred == label).float().mean()\n",
    "\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        val_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        val_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n",
    "\n",
    "        tensorboard_logs = {'val_loss': val_loss, 'val_acc': val_acc}\n",
    "        return {'val_loss': val_loss, 'log': tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam([p for p in self.parameters() if p.requires_grad], lr=2e-5, eps=1e-8)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7553e-01,  4.5944e-01, -7.7097e-02, -5.0726e-03, -8.3951e-02,\n",
       "         -3.0212e-01, -2.6951e-01,  1.0670e-01, -1.3731e-01, -6.2008e-02,\n",
       "          1.8305e-01, -2.6312e-01, -1.7207e-01, -9.2808e-02, -2.2290e-01,\n",
       "         -6.2406e-02,  2.1713e-01, -5.1994e-01,  2.7303e-02, -1.0409e-01,\n",
       "          1.9074e-01,  3.3966e-01, -2.4129e-01,  3.5506e-01],\n",
       "        [-1.9022e-01,  2.7270e-01, -1.7912e-01, -1.1672e-01, -2.1572e-01,\n",
       "         -1.5630e-01, -3.2160e-01, -1.2292e-01,  3.5839e-02, -2.1186e-01,\n",
       "          3.9432e-02, -2.6421e-01, -1.5557e-01,  1.1514e-01, -6.8680e-02,\n",
       "          3.5593e-02,  3.0314e-01, -4.6108e-01,  1.8311e-01, -1.7219e-01,\n",
       "         -1.9017e-02,  2.0428e-01, -7.1210e-02,  3.0772e-01],\n",
       "        [-2.4918e-01,  3.7341e-01, -5.9863e-02,  5.6676e-02, -3.1699e-01,\n",
       "         -4.2766e-02, -2.5928e-01, -1.6467e-01, -2.8753e-02, -2.7824e-01,\n",
       "          6.4833e-02, -2.7546e-01, -1.7615e-01, -1.1546e-01, -3.2999e-01,\n",
       "          1.2622e-04,  2.3403e-01, -3.7908e-01,  1.2669e-01, -1.1565e-01,\n",
       "          1.0586e-01,  1.9829e-01, -1.3004e-01,  2.3930e-01],\n",
       "        [-2.1047e-01,  2.8101e-01, -2.3990e-01, -1.1224e-01, -1.8008e-01,\n",
       "         -2.9514e-02, -4.1587e-01, -3.5793e-02,  1.5413e-01, -3.6789e-01,\n",
       "          1.8518e-01, -6.7061e-02, -1.0221e-01,  1.4569e-01, -1.8130e-01,\n",
       "          1.1295e-01,  3.7525e-01, -6.0703e-01,  3.5993e-01, -8.6960e-02,\n",
       "          1.5904e-01,  3.4620e-01,  6.5935e-02,  1.6781e-01],\n",
       "        [-3.5974e-01,  1.4882e-01, -2.0220e-03, -2.2867e-02, -5.1061e-01,\n",
       "         -3.1385e-01, -2.5503e-01,  3.4202e-03,  9.8539e-02, -2.2826e-01,\n",
       "          1.0834e-01, -1.4087e-01, -7.8602e-02,  1.8927e-01, -4.9224e-01,\n",
       "         -1.1070e-01,  2.7502e-01, -2.9267e-01,  1.1946e-01,  4.3660e-02,\n",
       "          1.7943e-01,  3.2529e-01,  3.9953e-02,  2.3891e-01],\n",
       "        [-2.2395e-01,  1.7502e-01, -1.3169e-02, -9.1722e-02, -2.1242e-01,\n",
       "         -1.8916e-01, -4.1260e-01,  9.7816e-02,  6.4452e-02, -1.2391e-01,\n",
       "          1.1553e-01, -2.7318e-01, -7.1744e-02, -2.5067e-02, -2.9437e-01,\n",
       "         -1.2633e-01,  3.2266e-01, -5.6035e-01,  1.6533e-02, -5.8500e-02,\n",
       "          1.1839e-01,  5.8855e-02,  2.0376e-02,  1.3423e-01],\n",
       "        [-3.1285e-01,  2.8553e-01, -2.1760e-01,  1.2227e-01, -1.5993e-01,\n",
       "         -1.8180e-01, -3.8069e-01, -1.7079e-01,  3.4638e-01, -3.0313e-01,\n",
       "          2.0034e-01, -1.0527e-01, -1.7024e-01,  1.8190e-01, -2.8155e-01,\n",
       "         -3.5551e-02,  3.0882e-01, -5.0403e-01,  1.4991e-01, -7.0321e-02,\n",
       "          6.2244e-02,  1.6488e-01,  3.4214e-02,  3.6458e-01],\n",
       "        [-2.5679e-01,  1.8069e-01, -2.4796e-02,  1.3788e-01, -3.2892e-01,\n",
       "         -2.2846e-02, -3.4426e-01, -6.5295e-02,  1.7402e-02, -2.9698e-01,\n",
       "          1.3567e-01, -1.4506e-01, -4.1253e-02, -7.1363e-03, -3.6440e-01,\n",
       "          8.3177e-03,  3.2372e-01, -5.1654e-01,  4.2114e-02, -1.6640e-01,\n",
       "         -4.3470e-03,  1.0564e-01,  6.2119e-02,  3.0400e-02],\n",
       "        [-2.0055e-01,  9.1955e-02, -9.6787e-02,  3.4342e-02, -3.7389e-01,\n",
       "         -2.2825e-01, -2.7160e-01, -7.7944e-02,  7.4221e-02, -1.6579e-01,\n",
       "          1.3608e-01, -1.9218e-01, -1.1133e-02,  1.0212e-01, -2.6024e-01,\n",
       "         -1.3188e-01,  2.0522e-01, -3.6481e-01,  3.1617e-01, -1.0384e-01,\n",
       "          9.2602e-02,  2.1892e-01, -5.6247e-02,  3.3206e-01],\n",
       "        [-2.1533e-01,  4.0837e-01, -1.7183e-01, -1.8138e-01, -2.6392e-01,\n",
       "         -9.6164e-02, -3.2724e-01,  2.1754e-01,  1.2583e-01, -3.7805e-01,\n",
       "          2.5806e-01, -2.7625e-01, -2.1107e-01,  2.7773e-01, -2.0154e-01,\n",
       "          1.3074e-02,  3.3815e-01, -4.5570e-01,  1.1721e-01, -1.5621e-01,\n",
       "          1.8241e-01,  4.2331e-01,  1.3846e-02,  1.5392e-01],\n",
       "        [-4.3353e-02,  4.4013e-01, -1.3622e-01, -1.0262e-01, -8.9612e-02,\n",
       "         -6.4103e-02, -4.4549e-01, -9.3338e-02,  1.8007e-01, -3.6622e-01,\n",
       "          2.0172e-01, -8.2558e-02, -2.0276e-01,  3.3284e-01, -7.2107e-02,\n",
       "          5.5223e-04,  3.6952e-01, -4.1455e-01,  2.2664e-01,  2.6543e-02,\n",
       "          1.6918e-01,  1.8962e-01,  5.2753e-02,  2.8125e-01],\n",
       "        [-4.4983e-02,  2.2258e-01, -3.0390e-01, -1.1449e-01, -2.3904e-01,\n",
       "         -1.4260e-01, -4.5000e-01, -1.8356e-01, -7.0010e-02, -4.0165e-01,\n",
       "          6.0135e-02, -1.8562e-01, -2.1850e-01,  1.4367e-01, -1.1879e-01,\n",
       "         -8.1504e-02,  3.0529e-01, -4.4098e-01,  8.5316e-02, -1.8275e-01,\n",
       "          1.0462e-01,  2.2115e-01, -2.4678e-01,  2.7061e-01],\n",
       "        [-2.1721e-01,  1.3961e-01, -1.3842e-01, -7.6908e-02, -3.6232e-01,\n",
       "         -9.1448e-02, -3.4405e-01, -3.9505e-02,  8.9313e-02, -3.9189e-01,\n",
       "          1.5954e-01, -1.3239e-01, -1.3421e-01, -1.2151e-02, -2.4320e-01,\n",
       "         -7.5511e-02,  3.4553e-01, -3.2798e-01,  6.6578e-02, -7.6830e-02,\n",
       "          1.0760e-01,  2.3568e-01, -1.6357e-01,  1.6371e-01],\n",
       "        [-2.7786e-01,  3.1557e-01, -1.0658e-01, -6.4446e-02, -3.4185e-01,\n",
       "         -1.9741e-01, -4.7961e-01, -7.4808e-02,  7.9207e-02, -2.8702e-01,\n",
       "          1.6928e-01, -9.6594e-02,  3.7588e-02,  2.8809e-01, -3.0023e-01,\n",
       "         -3.9693e-02,  3.3828e-01, -5.7795e-01,  2.0186e-01, -1.1699e-01,\n",
       "         -6.5297e-02,  3.0491e-01, -2.0530e-01,  1.4473e-01],\n",
       "        [-1.6755e-01,  3.5227e-01, -1.1389e-01,  1.1589e-01, -1.2001e-01,\n",
       "         -1.7076e-01, -6.5050e-01, -7.7478e-02,  1.3357e-01, -2.7984e-01,\n",
       "          8.2747e-02, -1.7131e-01, -2.3597e-01,  2.7434e-01, -1.5746e-01,\n",
       "          1.6866e-01,  4.6380e-01, -3.6569e-01,  4.1646e-01, -1.8268e-01,\n",
       "         -1.4743e-01,  6.3856e-02,  5.7984e-02,  4.3657e-01],\n",
       "        [-2.6075e-01,  3.4351e-01, -8.7502e-02,  5.9848e-02, -1.8094e-01,\n",
       "          6.7562e-02, -4.5398e-01, -5.3962e-02,  5.2338e-02, -3.5982e-01,\n",
       "          1.2374e-01, -1.7068e-01, -1.3771e-01, -4.9125e-02, -2.5399e-01,\n",
       "          3.0696e-02,  2.8767e-01, -3.7003e-01,  2.4971e-01,  1.0620e-02,\n",
       "          1.0376e-01,  1.0839e-01,  1.6851e-02,  8.3226e-02],\n",
       "        [-4.9976e-02,  3.8688e-01, -2.1427e-01, -1.0505e-01, -2.4594e-01,\n",
       "         -7.6057e-03, -3.3134e-01, -3.5145e-02,  8.2654e-02, -3.1522e-01,\n",
       "          2.4041e-01, -1.5963e-01, -9.1006e-02,  2.3018e-01, -6.5998e-02,\n",
       "         -1.1659e-01,  4.5656e-01, -4.6992e-01,  7.3306e-02, -1.1121e-02,\n",
       "          8.6720e-02,  1.2851e-01, -5.4746e-02,  1.4151e-01],\n",
       "        [-3.5507e-01,  3.2851e-01, -1.8345e-01, -1.2532e-01, -3.9882e-01,\n",
       "         -2.4084e-01, -3.5850e-01,  9.0272e-02,  8.8710e-02, -2.7454e-01,\n",
       "          1.2003e-01, -1.9100e-01, -1.6726e-01,  2.5642e-01, -2.4895e-01,\n",
       "          2.5008e-02,  1.4431e-01, -3.8552e-01,  4.8203e-02, -2.0712e-01,\n",
       "          2.2562e-01,  8.2188e-02, -1.4840e-01,  2.7641e-01],\n",
       "        [-3.5558e-01,  2.4430e-01, -1.0985e-01, -1.0134e-01, -4.5140e-01,\n",
       "         -2.4683e-01, -3.1368e-01, -1.0020e-01,  9.5990e-02, -3.7178e-01,\n",
       "          1.4162e-01, -2.6210e-01, -1.2577e-01,  1.7582e-01, -2.8294e-01,\n",
       "         -1.1703e-01,  2.2218e-01, -4.0636e-01,  1.6797e-01, -1.2685e-01,\n",
       "          1.2500e-01,  2.1929e-01, -1.1495e-01,  9.8580e-02],\n",
       "        [-3.2747e-01,  7.4608e-02, -1.6792e-02,  1.1519e-01, -4.9358e-01,\n",
       "          1.1245e-01, -3.2541e-01,  8.0187e-02,  1.3731e-01, -2.3097e-01,\n",
       "          1.0585e-01, -3.0970e-01, -5.6019e-02, -2.0994e-01, -2.3136e-01,\n",
       "          5.9596e-02,  1.2572e-01, -4.0849e-01,  6.7119e-02, -2.0052e-01,\n",
       "         -1.5013e-02,  7.6367e-02,  6.0330e-02,  1.6529e-01],\n",
       "        [-2.2940e-01,  2.0074e-01, -1.4181e-01, -1.5024e-01, -1.6702e-01,\n",
       "         -9.9926e-02, -3.3337e-01,  2.8721e-02,  1.1615e-01, -3.9804e-01,\n",
       "          1.9313e-01, -2.0051e-01, -9.9705e-02,  1.2039e-01, -3.0407e-01,\n",
       "         -1.0652e-01,  2.9418e-01, -3.7558e-01,  1.8891e-01,  3.4191e-02,\n",
       "          2.3806e-01,  1.1119e-01, -1.1909e-01,  1.7355e-01],\n",
       "        [-3.7397e-01,  3.6048e-01, -1.8668e-01, -1.1778e-01, -2.6031e-01,\n",
       "         -2.0278e-01, -2.5322e-01, -7.4970e-02,  1.2186e-01, -3.8321e-01,\n",
       "          2.5180e-01, -2.3175e-01, -2.0287e-01,  5.6801e-02, -2.5352e-01,\n",
       "         -4.2618e-02,  3.7958e-01, -4.9832e-01,  2.3418e-02,  4.6375e-03,\n",
       "          5.9864e-02,  4.0645e-01, -1.6703e-01,  2.5047e-01],\n",
       "        [-4.6081e-01,  2.8455e-01, -1.4660e-01,  4.3116e-02, -2.2492e-01,\n",
       "          1.5632e-02, -2.8615e-01,  2.2374e-01, -7.3887e-02, -4.3760e-01,\n",
       "          2.4133e-01, -1.6787e-01, -2.9660e-02,  8.4693e-02, -2.5330e-01,\n",
       "         -5.9022e-02,  3.6842e-01, -4.8598e-01,  1.7491e-01, -6.8939e-02,\n",
       "          9.3781e-02,  2.5240e-01,  6.1890e-02,  3.2353e-01],\n",
       "        [-1.8792e-01,  3.4299e-01, -2.3076e-01,  2.8613e-02, -2.2034e-01,\n",
       "         -2.7748e-01, -3.5252e-01, -7.3738e-02,  2.2121e-02, -3.5996e-01,\n",
       "          1.0283e-01, -8.7121e-02, -1.2880e-01,  2.4603e-01, -2.1443e-01,\n",
       "         -3.5777e-02,  3.2785e-01, -6.1081e-01,  4.2828e-02, -2.3102e-01,\n",
       "          1.0307e-01,  2.8949e-01, -1.7636e-01,  4.3044e-02],\n",
       "        [-3.2074e-01,  1.8683e-01, -2.0687e-01,  8.5633e-02, -3.9242e-01,\n",
       "         -3.4568e-02, -2.1062e-01, -1.0548e-02,  9.4132e-03, -3.7192e-01,\n",
       "          1.5514e-01, -1.9727e-01, -9.2961e-02,  1.1430e-01, -3.6139e-01,\n",
       "          1.4666e-01,  2.5924e-01, -3.8006e-01,  1.9628e-01, -8.4486e-02,\n",
       "         -3.7292e-03,  1.7733e-01, -5.1329e-02,  3.6430e-01],\n",
       "        [-1.1077e-01,  3.5786e-01, -2.0783e-01,  4.2603e-02, -4.5442e-01,\n",
       "         -2.2968e-01, -3.3897e-01, -3.0396e-02,  1.2975e-01, -3.0683e-02,\n",
       "          1.7244e-01, -1.8278e-01, -1.2113e-01,  1.9343e-01, -9.8048e-02,\n",
       "          1.1891e-01,  2.7317e-01, -3.2228e-01,  2.3087e-03, -4.0368e-02,\n",
       "          4.1635e-02,  1.9335e-01, -6.5049e-02,  2.6045e-01],\n",
       "        [-1.0630e-01,  4.7022e-01, -1.1326e-02, -6.5827e-02, -2.9419e-01,\n",
       "         -2.4143e-01, -3.3618e-01,  1.5373e-01,  5.8419e-02, -3.8011e-01,\n",
       "          1.3346e-01, -1.7023e-01, -2.7463e-01,  1.1617e-02, -4.9709e-02,\n",
       "          1.3584e-01,  3.3768e-01, -4.3880e-01,  1.3029e-01, -2.4995e-01,\n",
       "          9.8093e-02,  2.8795e-01, -8.0827e-02,  6.0671e-01],\n",
       "        [-1.1461e-01,  4.2293e-01, -1.6642e-01, -1.1669e-01, -2.5715e-01,\n",
       "         -6.0801e-02, -3.0736e-01, -1.3009e-01,  1.2532e-01, -1.9822e-01,\n",
       "          1.2835e-01,  1.0985e-02, -4.2477e-02,  2.6422e-01, -3.2692e-02,\n",
       "          2.0452e-02,  3.3690e-01, -3.4744e-01,  2.1908e-01, -1.5379e-01,\n",
       "          9.6178e-02,  1.9947e-01,  3.8620e-03,  2.1097e-01],\n",
       "        [-3.0920e-01,  2.5685e-01, -1.0743e-02, -7.6287e-02, -3.2228e-01,\n",
       "         -1.8793e-01, -2.8964e-01, -1.1205e-01,  1.6425e-01, -1.7761e-01,\n",
       "          1.1055e-01, -2.8991e-01, -2.1242e-01,  6.3449e-02, -1.8701e-01,\n",
       "         -9.8721e-02,  3.3645e-01, -4.0838e-01,  1.5764e-01, -1.7954e-01,\n",
       "          2.5979e-01,  1.6696e-01, -2.3816e-03,  4.6558e-02],\n",
       "        [-1.8887e-01,  2.8679e-01, -2.9867e-01, -2.5133e-02, -4.3068e-01,\n",
       "         -1.7661e-01, -4.8600e-01, -1.5614e-01,  1.2779e-01, -1.5033e-01,\n",
       "          7.3478e-02, -8.5362e-02, -6.5341e-02,  1.6813e-01, -2.5423e-01,\n",
       "         -1.9614e-02,  2.3943e-01, -5.3663e-01, -4.5364e-02, -1.1715e-01,\n",
       "          1.9258e-01,  4.3249e-01, -2.5869e-01,  1.0554e-01],\n",
       "        [-2.3499e-01,  2.3142e-01, -2.1740e-02,  8.8805e-02, -4.2056e-01,\n",
       "         -2.0332e-01, -4.2646e-01, -1.6323e-02,  1.1133e-01, -3.4074e-01,\n",
       "          2.0962e-01, -1.6469e-01, -1.8722e-02, -1.8786e-02, -2.9308e-01,\n",
       "         -1.5575e-01,  3.2293e-01, -4.4892e-01,  2.4752e-01, -7.4761e-02,\n",
       "          1.3644e-01,  1.0362e-01,  1.2204e-01,  1.9811e-01],\n",
       "        [-4.3400e-02,  3.1810e-01, -1.1707e-02, -6.2750e-02, -2.5505e-02,\n",
       "         -2.1284e-01, -4.0795e-01, -8.4707e-02, -1.0358e-02, -3.6849e-01,\n",
       "          2.2732e-01, -2.0165e-01, -2.0413e-01,  2.6961e-02, -1.4386e-01,\n",
       "          1.0143e-02,  1.9382e-01, -4.9286e-01,  1.3262e-01, -1.7146e-01,\n",
       "          8.5322e-02,  1.8985e-01, -7.9512e-02,  1.9478e-01]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ETRoBERTaModel(roberta_path, train_loader, valid_loader)\n",
    "batch = next(iter(train_loader))\n",
    "model(batch[0], batch[1], batch[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                          | Params\n",
      "------------------------------------------------------------\n",
      "0 | ptm       | BertForSequenceClassification | 325 M \n",
      "1 | criterion | CrossEntropyLoss              | 0     \n",
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d609ebf5b4634360bec0814e1ba277bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    val_check_interval=0.1,\n",
    "    gpus=1,\n",
    "    distributed_backend='dp',\n",
    "    weights_save_path='./pytorch-lightning-checkpoints/ETRoBERTaModel',\n",
    ")\n",
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
